{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "__author__ = 'aifa'\n",
      "\n",
      "import os\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "\n",
      "from sklearn import clone\n",
      "\n",
      "from sklearn.ensemble.weight_boosting import AdaBoostClassifier\n",
      "from sklearn.ensemble.forest import (RandomForestClassifier,RandomForestRegressor,\n",
      "                                        ExtraTreesClassifier)\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn import svm\n",
      "\n",
      "import math as math\n",
      "from sklearn.externals.six.moves import xrange\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "from sklearn.svm import SVR\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "\n",
      "from sklearn.feature_selection import RFE\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.feature_selection import RFECV\n",
      "from sklearn.metrics import zero_one_loss\n",
      "\n",
      "train_sets={}\n",
      "train_1 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_1.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[1]=train_1\n",
      "train_2 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_2.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[2]=train_2\n",
      "train_3 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_3.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[3]=train_3\n",
      "train_4 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_4.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[4]=train_4\n",
      "train_5 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_5.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[5]=train_5\n",
      "train_6 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_6.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[6]=train_6\n",
      "train_7 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_7.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[7]=train_7\n",
      "train_8 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_8.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[8]=train_8\n",
      "train_9 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_9.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[9]=train_9\n",
      "train_10 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_10.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[10]=train_10\n",
      "train_11 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_11.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[11]=train_11\n",
      "train_12 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_12.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[12]=train_12\n",
      "\n",
      "test_2 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/test_v2_all_future.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "\n",
      "\n",
      "results_df = pd.DataFrame(index=test_2.index)\n",
      "resultCol = pd.Series(index=test_2.index,dtype=object)\n",
      "\n",
      "#try random forest on feature A\n",
      "n_estimators = 100\n",
      "\n",
      "rfcModel = RandomForestClassifier(n_estimators=n_estimators, max_features=None)\n",
      "rfrmodel = RandomForestRegressor(n_estimators=n_estimators)\n",
      "lr = LogisticRegression()\n",
      "\n",
      "\n",
      "#svr =  SVR(C=1.0, epsilon=0.2)\n",
      "C = 1.0  # SVM regularization parameter\n",
      "svc = svm.SVC(kernel='linear', C=C)\n",
      "#rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=C)\n",
      "#poly_svc = svm.SVC(kernel='poly', degree=3, C=C)\n",
      "\n",
      "def cleanup(df):\n",
      "\n",
      "    #find columns that contain null values\n",
      "    inds = pd.isnull(df).any(0).nonzero()\n",
      "\n",
      "    df['car_value'] = df['car_value'].fillna('0')\n",
      "    df['car_value']=df['car_value'].apply(lambda letter :  abs(ord(letter) - 96))\n",
      "    df['state']=df['state'].apply(lambda letter :  abs(ord(letter[0]) - 96 + ord(letter[1]) - 96))\n",
      "\n",
      "    #remove product feature\n",
      "    #df=df.drop(['product'], axis=1)\n",
      "    #df=df.drop(['state'], axis=1)\n",
      "    #df=df.drop(['location'], axis=1)\n",
      "    df=df.drop(['time'], axis=1)\n",
      "\n",
      "    #impute the null values\n",
      "    df['risk_factor'] = df['risk_factor'].fillna(0)\n",
      "    df['C_previous'] = df['C_previous'].fillna(0)\n",
      "    df['duration_previous'] = df['duration_previous'].fillna(0)\n",
      "    df['location'] = df['location'].fillna(0)\n",
      "\n",
      "    df['A_var'] = df['A_var'].fillna(0)\n",
      "    df['B_var'] = df['B_var'].fillna(0)\n",
      "    df['C_var'] = df['C_var'].fillna(0)\n",
      "    df['D_var'] = df['D_var'].fillna(0)\n",
      "    df['E_var'] = df['E_var'].fillna(0)\n",
      "    df['F_var'] = df['F_var'].fillna(0)\n",
      "    df['G_var'] = df['G_var'].fillna(0)\n",
      "    df['cost_var'] = df['cost_var'].fillna(0)\n",
      "    #drop any other rows that might contain null values (at this point only lines with empty key cols should be removed from the training sets)\n",
      "    df=df.dropna()\n",
      "\n",
      "    return df\n",
      "\n",
      "def cleanup_test(df):\n",
      "\n",
      "    #find columns that contain null values\n",
      "    inds = pd.isnull(df).any(0).nonzero()\n",
      "\n",
      "    df['car_value'] = df['car_value'].fillna('0')\n",
      "    df['car_value']=df['car_value'].apply(lambda letter :  abs(ord(letter) - 96))\n",
      "    df['state']=df['state'].apply(lambda letter :  abs(ord(letter[0]) - 96 + ord(letter[1]) - 96))\n",
      "\n",
      "    #remove product feature\n",
      "    #df=df.drop(['product'], axis=1)\n",
      "    #df=df.drop(['state'], axis=1)\n",
      "    #df=df.drop(['location'], axis=1)\n",
      "    df=df.drop(['time'], axis=1)\n",
      "    \n",
      "    #impute the null values\n",
      "    df['risk_factor'] = df['risk_factor'].fillna(0)\n",
      "    df['C_previous'] = df['C_previous'].fillna(0)\n",
      "    df['duration_previous'] = df['duration_previous'].fillna(0)\n",
      "    df['location'] = df['location'].fillna(0)\n",
      "\n",
      "    df['A_var'] = df['A_var'].fillna(0)\n",
      "    df['B_var'] = df['B_var'].fillna(0)\n",
      "    df['C_var'] = df['C_var'].fillna(0)\n",
      "    df['D_var'] = df['D_var'].fillna(0)\n",
      "    df['E_var'] = df['E_var'].fillna(0)\n",
      "    df['F_var'] = df['F_var'].fillna(0)\n",
      "    df['G_var'] = df['G_var'].fillna(0)\n",
      "    df['cost_var'] = df['cost_var'].fillna(0)\n",
      "\n",
      "    return df\n",
      "\n",
      "def select_features(train_df, select_model, yName='A_purchase'):\n",
      "    input_df = train_df.copy(deep=True)\n",
      "    y = input_df[yName].values\n",
      "    \n",
      "    input_df=input_df.drop(['total_offers'], axis=1)\n",
      "    input_df=input_df.drop(['A_purchase'], axis=1)\n",
      "    input_df=input_df.drop(['B_purchase'], axis=1)\n",
      "    input_df=input_df.drop(['C_purchase'], axis=1)\n",
      "    input_df=input_df.drop(['D_purchase'], axis=1)\n",
      "    input_df=input_df.drop(['E_purchase'], axis=1)\n",
      "    input_df=input_df.drop(['F_purchase'], axis=1)\n",
      "    input_df=input_df.drop(['G_purchase'], axis=1)\n",
      "\n",
      "    #if (yName=='G_purchase'):\n",
      "    #    input_df=input_df.drop(['C_previous'], axis=1)\n",
      "\n",
      "\n",
      "    X = input_df.values\n",
      "\n",
      "  # Create the RFE object and compute a cross-validated score.\n",
      "    #svc = SVC(kernel=\"linear\")\n",
      "    rfecv = RFECV(estimator=select_model,\n",
      "                  step=1,\n",
      "                  cv=StratifiedKFold(y, 3),\n",
      "                  scoring=\"f1\")\n",
      "    rfecv.fit(X, y)\n",
      "\n",
      "    print \"Optimal number of features : %d\" % rfecv.n_features_\n",
      "    \n",
      "    # Plot number of features VS. cross-validation scores\n",
      "    #pl.figure()\n",
      "    #pl.xlabel(\"Number of features selected\")\n",
      "    #pl.ylabel(\"Cross validation score (nb of misclassifications)\")\n",
      "    #pl.plot(xrange(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
      "    #pl.show()\n",
      "    \n",
      "    idx=0\n",
      "    for i in input_df.columns:\n",
      "        if (rfecv.support_[idx]==False):\n",
      "            input_df=input_df.drop([i], axis=1)\n",
      "        idx += 1\n",
      "        \n",
      "    print input_df.columns\n",
      "    \n",
      "    return input_df.columns\n",
      "\n",
      "def predict(test_2_df, model, prodStr='A_purchase'):\n",
      "\n",
      "    test_df = test_2_df.copy(deep=True)\n",
      "    test_y = test_df[prodStr]\n",
      "\n",
      "    if prodStr=='total_offers':\n",
      "        test_df=test_df.drop([prodStr])\n",
      "    else:\n",
      "        test_df=test_df.drop(['A_purchase'])\n",
      "        test_df=test_df.drop(['B_purchase'])\n",
      "        test_df=test_df.drop(['C_purchase'])\n",
      "        test_df=test_df.drop(['D_purchase'])\n",
      "        test_df=test_df.drop(['E_purchase'])\n",
      "        test_df=test_df.drop(['F_purchase'])\n",
      "        test_df=test_df.drop(['G_purchase'])\n",
      "\n",
      "    if (prodStr=='G_purchase'):\n",
      "        test_df=test_df.drop(['C_previous'])\n",
      "\n",
      "    test_X = test_df.values\n",
      "\n",
      "    prediction = model.predict(test_X)\n",
      "\n",
      "    #print prodStr +\":\"+str(prediction)\n",
      "\n",
      "    return prediction\n",
      "\n",
      "for offers in range(1,13):\n",
      "    train = cleanup(train_sets[offers])\n",
      "    print \"--------Number of offers:\" + str(offers)\n",
      "    print len(train.columns)\n",
      "    \n",
      "    print 'A:'\n",
      "    select_features(train, svc)\n",
      "    print 'B:'\n",
      "    select_features(train, svc, yName='B_purchase')\n",
      "    print 'C:'\n",
      "    select_features(train, svc, yName='C_purchase')\n",
      "    print 'D:'\n",
      "    select_features(train, svc, yName='D_purchase')\n",
      "    print 'E:'\n",
      "    select_features(train, svc, yName='E_purchase')\n",
      "    print 'F:'\n",
      "    select_features(train, svc, yName='F_purchase')\n",
      "    print 'G:'\n",
      "    select_features(train, svc, yName='G_purchase')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}