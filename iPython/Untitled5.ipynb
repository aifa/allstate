{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "\n",
      "from sklearn import clone\n",
      "\n",
      "from sklearn.svm import LinearSVC\n",
      "\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "from sklearn.decomposition import PCA, KernelPCA\n",
      "\n",
      "# note: these imports are incorrect in the example online!\n",
      "from sklearn.ensemble.weight_boosting import AdaBoostClassifier\n",
      "from sklearn.ensemble.forest import (RandomForestClassifier,\n",
      "                                        ExtraTreesClassifier)\n",
      "\n",
      "from sklearn import svm\n",
      "\n",
      "import math as math\n",
      "from sklearn.externals.six.moves import xrange\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "train = pd.read_csv(\"./Dropbox/kaggle/insurance/transformed/train_transformed.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "test_2 = pd.read_csv(\"./Dropbox/kaggle/insurance/transformed/test_v2_transformed.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "\n",
      "results_df = pd.DataFrame(index=test_2.index)\n",
      "resultCol = pd.Series(index=test_2.index,dtype=object)\n",
      "\n",
      "#try random forest on feature A\n",
      "n_estimators = 30\n",
      "\n",
      "decision_tree = DecisionTreeClassifier()\n",
      "rfcmodel = RandomForestClassifier(n_estimators=n_estimators)\n",
      "\n",
      "C = 10.0  # SVM regularization parameter\n",
      "svc = svm.SVC(kernel='linear', C=C)\n",
      "rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=C)\n",
      "poly_svc = svm.SVC(kernel='poly', degree=3, C=C)\n",
      "\n",
      "def cleanup(df):\n",
      "\n",
      "    #find columns that contain null values\n",
      "    inds = pd.isnull(df).any(0).nonzero()\n",
      "\n",
      "    df['car_value'] = df['car_value'].fillna('0')\n",
      "    df['car_value']=df['car_value'].apply(lambda letter :  ord(letter) - 96)\n",
      "\n",
      "    #remove product feature\n",
      "    df=df.drop(['product'], axis=1)\n",
      "    df=df.drop(['state'], axis=1)\n",
      "    df=df.drop(['location'], axis=1)\n",
      "    df=df.drop(['time'], axis=1)\n",
      "\n",
      "\n",
      "\n",
      "    #impute the null values\n",
      "    df['risk_factor'] = df['risk_factor'].fillna(0)\n",
      "    df['C_previous'] = df['C_previous'].fillna(0)\n",
      "    df['duration_previous'] = df['duration_previous'].fillna(0)\n",
      "\n",
      "    return df\n",
      "\n",
      "def predict(train_df, test_2_df, model, prodStr='A'):\n",
      "\n",
      "    input_df = train_df.copy(deep=True)\n",
      "    test_df = test_2_df.copy(deep=True)\n",
      "\n",
      "    input_df = cleanup(input_df)\n",
      "    test_df = cleanup(test_df)\n",
      "\n",
      "    y = input_df[prodStr].values\n",
      "    input_df=input_df.drop([prodStr], axis=1)\n",
      "    X = input_df.values[:,2:]\n",
      "\n",
      "    test_y = test_df[prodStr].values\n",
      "    test_df=test_df.drop([prodStr], axis=1)\n",
      "    test_X = test_df.values[:,2:]\n",
      "\n",
      "    # Shuffle\n",
      "    idx = np.arange(X.shape[0])\n",
      "    np.random.seed(13)\n",
      "    np.random.shuffle(idx)\n",
      "    X = X[idx]\n",
      "    y = y[idx]\n",
      "\n",
      "   # lsvc = LinearSVC()\n",
      "   # X_trans = lsvc.fit_transform(X,y)\n",
      "    pca = PCA(n_components=2)\n",
      "    \n",
      "    #kpca = KernelPCA(kernel=\"rbf\", fit_inverse_transform=True, gamma=10)\n",
      "    #X_kpca = kpca.fit_transform(X)\n",
      "    #test_X_kpca = kpca.fit_transform(test_X)\n",
      "    #pca = pca.fit(X)\n",
      "    #X_pca = pca.transform(X)\n",
      "    #test_X_pca = pca.transform(test_X)\n",
      "    \n",
      "    clf = clone(model)\n",
      "    clf = clf.fit(X, y)\n",
      "\n",
      "    \n",
      "    tree = clf.predict(test_X)\n",
      "\n",
      "    print clf.score(test_X,test_y)\n",
      "\n",
      "    z=[tree==test_y]\n",
      "\n",
      "    return tree\n",
      "\n",
      "change=predict(train, test_2,decision_tree,prodStr='prod_change')\n",
      "A= predict(train, test_2,decision_tree)\n",
      "B= predict(train, test_2,decision_tree,prodStr='B')\n",
      "C= predict(train, test_2,decision_tree,prodStr='C')\n",
      "D= predict(train, test_2,decision_tree,prodStr='D')\n",
      "E= predict(train, test_2,decision_tree,prodStr='E')\n",
      "F= predict(train, test_2,decision_tree,prodStr='F')\n",
      "G= predict(train, test_2,decision_tree,prodStr='G')\n",
      "\n",
      "correct=0\n",
      "for i in range(0,np.size(A)):\n",
      "    if test_2.prod_change.iat[i]<change[i]:\n",
      "        resultCol.iat[i]=str(A[i])+str(B[i])+str(C[i])+str(D[i])+str(E[i])+str(F[i])+str(G[i])\n",
      "    else:\n",
      "        resultCol.iat[i]=str(test_2.A.iat[i])+str(test_2.B.iat[i])+str(test_2.C.iat[i])+\\\n",
      "                         str(test_2.D.iat[i])+str(test_2.E.iat[i])+str(test_2.F.iat[i])+str(test_2.G.iat[i])\n",
      "\n",
      "    if test_2.A.iat[i]==float(strA) and test_2.B.iat[i]==float(strB) and test_2.C.iat[i]==float(strC) and test_2.D.iat[i]==float(strD)\\\n",
      "        and test_2.E.iat[i]==float(strE) and test_2.F.iat[i]==float(strF) and test_2.G.iat[i]==float(strG):\n",
      "        correct = correct+1\n",
      "\n",
      "\n",
      "\n",
      "print correct/len(test_2)\n",
      "#results_df[\"plan\"]=resultCol\n",
      "#results_df.to_csv(\"results.csv\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.423145954483\n",
        "0.861206834661"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.769204537296"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.733128724244"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.787547562639"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.793183286668"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.668371742408"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.47734941489"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "float(str(1.0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if (float(str(1.0))==1.0):\n",
      "    print \"yes\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "yes\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "__author__ = 'aifa'\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import dateutil.parser as dtparser\n",
      "import datetime as dt\n",
      "\n",
      "def cartesian(arrays, out=None):\n",
      "    \"\"\"\n",
      "    Generate a cartesian product of input arrays.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arrays : list of array-like\n",
      "        1-D arrays to form the cartesian product of.\n",
      "    out : ndarray\n",
      "        Array to place the cartesian product in.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
      "        formed of input arrays.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    # cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
      "    array([[1, 4, 6],\n",
      "           [1, 4, 7],\n",
      "           [1, 5, 6],\n",
      "           [1, 5, 7],\n",
      "           [2, 4, 6],\n",
      "           [2, 4, 7],\n",
      "           [2, 5, 6],\n",
      "           [2, 5, 7],\n",
      "           [3, 4, 6],\n",
      "           [3, 4, 7],\n",
      "           [3, 5, 6],\n",
      "           [3, 5, 7]])\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    arrays = [np.asarray(x) for x in arrays]\n",
      "    dType = arrays[0].dtype\n",
      "\n",
      "    n = np.prod([x.size for x in arrays])\n",
      "    if out is None:\n",
      "        out = np.zeros([n, len(arrays)], dtype=dType)\n",
      "\n",
      "    m = n / arrays[0].size\n",
      "    out[:, 0] = np.repeat(arrays[0], m)\n",
      "    if arrays[1:]:\n",
      "        cartesian(arrays[1:], out=out[0:m, 1:])\n",
      "        for j in xrange(1, arrays[0].size):\n",
      "            out[j * m:(j + 1) * m, 1:] = out[0:m, 1:]\n",
      "    return out\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def transform(fileName):\n",
      "\n",
      "    input_df = pd.read_csv(fileName, header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "\n",
      "    #print train_df.head()\n",
      "\n",
      "    print input_df.columns\n",
      "\n",
      "    #create all available product option combinations\n",
      "    A = (0, 1, 2)\n",
      "    B = (0, 1)\n",
      "    C = (1, 2, 3, 4)\n",
      "    D = (1, 2, 3)\n",
      "    E = (0, 1)\n",
      "    F = (0, 1, 2, 3)\n",
      "    G = (1, 2, 3, 4)\n",
      "\n",
      "    #produce an array with all the possible options combinations\n",
      "    combos = cartesian((A, B, C, D, E, F, G))\n",
      "    #print (list(train_df['A'].values),list(train_df['B'].values),list(train_df['C'].values),list(train_df['D'].values),\n",
      "    #       list(train_df['E'].values),list(train_df['F'].values),list(train_df['G'].values))[1][1]\n",
      "    #print train_df.values[:,17:24].searchsorted(combos)\n",
      "    #print combos\n",
      "    #print combos.size\n",
      "    def comboCompare(row, values):\n",
      "        return (row[0] == values[0] and row[1] == values[1] and row[2] == values[2] and row[3] == values[3] and row[4] ==\n",
      "            values[4] and row[5] == values[5] and row[6] == values[6]) == True\n",
      "\n",
      "\n",
      "    def findCombo(row, cCombos=combos):\n",
      "        currentCombo = (row.values[16:23])\n",
      "        return np.where(np.apply_along_axis(comboCompare, 1, cCombos, currentCombo) == True)[0][0]\n",
      "\n",
      "    train_df = input_df.copy(deep=True)\n",
      "    #add product combo column\n",
      "    #train_df[\"product\"] = train_df.apply(findCombo, axis=1)\n",
      "\n",
      "    #checkpoint to backup changes\n",
      "    train_df.to_csv(fileName+\"_checkpoint.csv\")\n",
      "\n",
      "    #create an dictionary that groups rows per customer id\n",
      "    customerDict = {}\n",
      "    for row in train_df.iterrows():\n",
      "        if not customerDict.has_key(row[0]):\n",
      "            customerDict[row[0]] = train_df[train_df.index == row[0]].copy()\n",
      "\n",
      "    #create an empty data frame with a unique entry per customer id\n",
      "    trans_df = pd.DataFrame(index=train_df.index, columns=train_df.columns.tolist())\n",
      "    trans_df = trans_df.groupby(level=0).last()\n",
      "    #define extra cols as series\n",
      "    initPriceCol = pd.Series(index=trans_df.index)\n",
      "    initACol = pd.Series(index=trans_df.index)\n",
      "    initBCol = pd.Series(index=trans_df.index)\n",
      "    initCCol = pd.Series(index=trans_df.index)\n",
      "    initDCol = pd.Series(index=trans_df.index)\n",
      "    initECol = pd.Series(index=trans_df.index)\n",
      "    initFCol = pd.Series(index=trans_df.index)\n",
      "    initGCol = pd.Series(index=trans_df.index)\n",
      "    #prodChangeCol = pd.Series(index=trans_df.index)\n",
      "    AchangeCol = pd.Series(index=trans_df.index)\n",
      "    BchangeCol = pd.Series(index=trans_df.index)\n",
      "    CchangeCol = pd.Series(index=trans_df.index)\n",
      "    DchangeCol = pd.Series(index=trans_df.index)\n",
      "    EchangeCol = pd.Series(index=trans_df.index)\n",
      "    FchangeCol = pd.Series(index=trans_df.index)\n",
      "    GchangeCol = pd.Series(index=trans_df.index)\n",
      "    durationCol = pd.Series(index=trans_df.index)\n",
      "    totalOffersCol = pd.Series(index=trans_df.index)\n",
      "    priceChangeCol = pd.Series(index=trans_df.index)\n",
      "\n",
      "    ####\n",
      "    #print(train_df.dtypes)\n",
      "\n",
      "    #for index_val, sub_df in train_df.groupby(level=0):\n",
      "    #    first_row = sub_df['Colname1', 'Colname2'].iloc[0, :]\n",
      "\n",
      "    #   (sub_df.product.diff() != 0).fillna(False).sum()\n",
      "\n",
      "\n",
      "    #for key, cDf in customerDict.iteritems():\n",
      "\n",
      "    ####\n",
      "\n",
      "    for key, cDf in customerDict.iteritems():\n",
      "        print \"transforming customer:\" + str(key)\n",
      "\n",
      "        index = 0\n",
      "        currentProduct = -1\n",
      "        #record how many times has the product changed\n",
      "        productChange = -1\n",
      "        initialPrice = -1\n",
      "        finalPrice = 0\n",
      "        startTime=None\n",
      "        endTime=None\n",
      "        startDay=0\n",
      "        endDay=0\n",
      "        durationHours=-1\n",
      "        initialProduct=-1\n",
      "\n",
      "        #price change between first offer and final product\n",
      "        priceChange=-1\n",
      "        totalRows=len(cDf.index)\n",
      "\n",
      "\n",
      "        for cRow in cDf.values:\n",
      "            recordType = int(cRow[1])\n",
      "           # product = int(cRow[24])\n",
      "            price = int(cRow[23])\n",
      "            time=dtparser.parse(cRow[3])\n",
      "            day=int(cRow[2])\n",
      "            #first offer\n",
      "            if index == 0:\n",
      "                initialPrice = price\n",
      "                startTime=time\n",
      "                startDay=day\n",
      "                #initialProduct=product\n",
      "\n",
      "\n",
      "           # if product != currentProduct:\n",
      "           #     currentProduct = product\n",
      "           #     productChange += 1\n",
      "\n",
      "#            if recordType == 0:\n",
      "#                pass\n",
      "            # bought product or last available offer\n",
      "            if recordType == 1 or index == totalRows-1:\n",
      "                trans_df.loc[key] = cRow\n",
      "                endDay=day\n",
      "                endTime=time\n",
      "                finalPrice = price\n",
      "                priceChange=finalPrice-initialPrice\n",
      "                days=endDay-startDay\n",
      "                if days>0:\n",
      "                    durationHours=days*24\n",
      "                else:\n",
      "                    durationHours = endTime.hour-startTime.hour\n",
      "            index += 1\n",
      "\n",
      "        initPriceCol.loc[key] = initialPrice\n",
      "        #initProductCol.loc[key] = initialProduct\n",
      "        #prodChangeCol.loc[key] = productChange\n",
      "        durationCol.loc[key] = durationHours\n",
      "        totalOffersCol.loc[key] = totalRows\n",
      "        priceChangeCol.loc[key] = cDf.cost.var()\n",
      "#        AchangeCol.loc[key]=(cDf.A.diff() != 0).fillna(False).sum()\n",
      "#        BchangeCol.loc[key]=(cDf.B.diff() != 0).fillna(False).sum()\n",
      "#        CchangeCol.loc[key]=(cDf.C.diff() != 0).fillna(False).sum()\n",
      "#        DchangeCol.loc[key]=(cDf.D.diff() != 0).fillna(False).sum()\n",
      "#        EchangeCol.loc[key]=(cDf.E.diff() != 0).fillna(False).sum()\n",
      "#        FchangeCol.loc[key]=(cDf.F.diff() != 0).fillna(False).sum()\n",
      "#        GchangeCol.loc[key]=(cDf.G.diff() != 0).fillna(False).sum()\n",
      "        AchangeCol.loc[key]=cDf.A.var()\n",
      "        BchangeCol.loc[key]=cDf.B.var()\n",
      "        CchangeCol.loc[key]=cDf.C.var()\n",
      "        DchangeCol.loc[key]=cDf.D.var()\n",
      "        EchangeCol.loc[key]=cDf.E.var()\n",
      "        FchangeCol.loc[key]=cDf.F.var()\n",
      "        GchangeCol.loc[key]=cDf.G.var()\n",
      "        initACol.loc[key]= cDf['A'].iloc[0]\n",
      "        initBCol.loc[key]= cDf['B'].iloc[0]\n",
      "        initCCol.loc[key]= cDf['C'].iloc[0]\n",
      "        initDCol.loc[key]= cDf['D'].iloc[0]\n",
      "        initECol.loc[key]= cDf['E'].iloc[0]\n",
      "        initFCol.loc[key]= cDf['F'].iloc[0]\n",
      "        initGCol.loc[key]= cDf['G'].iloc[0]\n",
      "\n",
      "    trans_df[\"init_price\"] = initPriceCol\n",
      "    #trans_df[\"init_product\"] = initProductCol\n",
      "    #trans_df[\"prod_change\"] = prodChangeCol\n",
      "    trans_df[\"duration_offers\"] = durationCol\n",
      "    trans_df[\"total_offers\"] = totalOffersCol\n",
      "    trans_df[\"price_change\"] = priceChangeCol\n",
      "\n",
      "    trans_df[\"A_init\"] = initACol\n",
      "    trans_df[\"B_init\"] = initBCol\n",
      "    trans_df[\"C_init\"] = initCCol\n",
      "    trans_df[\"D_init\"] = initDCol\n",
      "    trans_df[\"E_init\"] = initECol\n",
      "    trans_df[\"F_init\"] = initFCol\n",
      "    trans_df[\"G_init\"] = initGCol\n",
      "\n",
      "    trans_df[\"A_change\"] = AchangeCol\n",
      "    trans_df[\"B_change\"] = BchangeCol\n",
      "    trans_df[\"C_change\"] = CchangeCol\n",
      "    trans_df[\"D_change\"] = DchangeCol\n",
      "    trans_df[\"E_change\"] = EchangeCol\n",
      "    trans_df[\"F_change\"] = FchangeCol\n",
      "    trans_df[\"G_change\"] = GchangeCol\n",
      "\n",
      "    trans_df.to_csv(fileName + \"_transformed_2.csv\")\n",
      "\n",
      "\n",
      "#transform(\"test_v2.csv\")\n",
      "transform(\"./Dropbox/kaggle/insurance/train.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-14-ad6890cc3756>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;31m#transform(\"test_v2.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Dropbox/kaggle/insurance/train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-14-ad6890cc3756>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(fileName)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcustomerDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mcustomerDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m#create an empty data frame with a unique entry per customer id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1691\u001b[0m             \u001b[0;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1693\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1694\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'shopping_pt', u'record_type', u'day', u'time', u'state', u'location', u'group_size', u'homeowner', u'car_age', u'car_value', u'risk_factor', u'age_oldest', u'age_youngest', u'married_couple', u'C_previous', u'duration_previous', u'A', u'B', u'C', u'D', u'E', u'F', u'G', u'cost'], dtype='object')\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}