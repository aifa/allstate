{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "__author__ = 'aifa'\n",
      "\n",
      "import os\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "from time import time\n",
      "\n",
      "from sklearn import clone\n",
      "\n",
      "from sklearn.ensemble.weight_boosting import AdaBoostClassifier\n",
      "from sklearn.ensemble.forest import (RandomForestClassifier,RandomForestRegressor,\n",
      "                                        ExtraTreesClassifier)\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn import svm\n",
      "\n",
      "import math as math\n",
      "from sklearn.externals.six.moves import xrange\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "from sklearn.svm import SVR\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "\n",
      "from sklearn.feature_selection import RFE\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.decomposition import RandomizedPCA\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "train_sets={}\n",
      "train_1 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_1.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[1]=train_1\n",
      "train_2 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_2.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[2]=train_2\n",
      "train_3 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_3.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[3]=train_3\n",
      "train_4 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_4.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[4]=train_4\n",
      "train_5 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_5.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[5]=train_5\n",
      "train_6 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_6.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[6]=train_6\n",
      "train_7 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_7.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[7]=train_7\n",
      "train_8 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_8.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[8]=train_8\n",
      "train_9 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_9.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[9]=train_9\n",
      "train_10 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_10.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[10]=train_10\n",
      "train_11 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_11.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[11]=train_11\n",
      "train_12 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/train_all_split_12.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "train_sets[12]=train_12\n",
      "\n",
      "test_2 = pd.read_csv(\"/Users/aifa/Dropbox/kaggle/insurance/future/test_v2_all_future.csv\", header=0, encoding=\"UTF-8\", error_bad_lines=False, sep=\",\", index_col=0)\n",
      "\n",
      "\n",
      "results_df = pd.DataFrame(index=test_2.index)\n",
      "resultCol = pd.Series(index=test_2.index,dtype=object)\n",
      "\n",
      "def cleanup(df):\n",
      "\n",
      "    #find columns that contain null values\n",
      "    inds = pd.isnull(df).any(0).nonzero()\n",
      "\n",
      "    df['car_value'] = df['car_value'].fillna('0')\n",
      "    df['car_value']=df['car_value'].apply(lambda letter :  abs(ord(letter) - 96))\n",
      "    df['state']=df['state'].apply(lambda letter :  abs(ord(letter[0]) - 96 + ord(letter[1]) - 96))\n",
      "\n",
      "    #remove product feature\n",
      "    #df=df.drop(['product'], axis=1)\n",
      "    #df=df.drop(['state'], axis=1)\n",
      "    #df=df.drop(['location'], axis=1)\n",
      "    df=df.drop(['time'], axis=1)\n",
      "\n",
      "    #impute the null values\n",
      "    df['risk_factor'] = df['risk_factor'].fillna(0)\n",
      "    df['C_previous'] = df['C_previous'].fillna(0)\n",
      "    df['duration_previous'] = df['duration_previous'].fillna(0)\n",
      "    df['location'] = df['location'].fillna(0)\n",
      "\n",
      "    df['A_var'] = df['A_var'].fillna(0)\n",
      "    df['B_var'] = df['B_var'].fillna(0)\n",
      "    df['C_var'] = df['C_var'].fillna(0)\n",
      "    df['D_var'] = df['D_var'].fillna(0)\n",
      "    df['E_var'] = df['E_var'].fillna(0)\n",
      "    df['F_var'] = df['F_var'].fillna(0)\n",
      "    df['G_var'] = df['G_var'].fillna(0)\n",
      "    df['cost_var'] = df['cost_var'].fillna(0)\n",
      "    #drop any other rows that might contain null values (at this point only lines with empty key cols should be removed from the training sets)\n",
      "    df=df.dropna()\n",
      "\n",
      "    return df\n",
      "\n",
      "def cleanup_test(df):\n",
      "\n",
      "    #find columns that contain null values\n",
      "    inds = pd.isnull(df).any(0).nonzero()\n",
      "\n",
      "    df['car_value'] = df['car_value'].fillna('0')\n",
      "    df['car_value']=df['car_value'].apply(lambda letter :  abs(ord(letter) - 96))\n",
      "    df['state']=df['state'].apply(lambda letter :  abs(ord(letter[0]) - 96 + ord(letter[1]) - 96))\n",
      "\n",
      "    #remove product feature\n",
      "    #df=df.drop(['product'], axis=1)\n",
      "    #df=df.drop(['state'], axis=1)\n",
      "    #df=df.drop(['location'], axis=1)\n",
      "    df=df.drop(['time'], axis=1)\n",
      "    \n",
      "    #impute the null values\n",
      "    df['risk_factor'] = df['risk_factor'].fillna(0)\n",
      "    df['C_previous'] = df['C_previous'].fillna(0)\n",
      "    df['duration_previous'] = df['duration_previous'].fillna(0)\n",
      "    df['location'] = df['location'].fillna(0)\n",
      "\n",
      "    df['A_var'] = df['A_var'].fillna(0)\n",
      "    df['B_var'] = df['B_var'].fillna(0)\n",
      "    df['C_var'] = df['C_var'].fillna(0)\n",
      "    df['D_var'] = df['D_var'].fillna(0)\n",
      "    df['E_var'] = df['E_var'].fillna(0)\n",
      "    df['F_var'] = df['F_var'].fillna(0)\n",
      "    df['G_var'] = df['G_var'].fillna(0)\n",
      "    df['cost_var'] = df['cost_var'].fillna(0)\n",
      "\n",
      "    return df\n",
      "\n",
      "def train_pca_SVC(train_df, yName='A_purchase'):\n",
      "    input_df = train_df.copy(deep=True)\n",
      "    y = input_df[yName].values\n",
      "\n",
      "    input_df=input_df.drop(['A_purchase'], axis=1)\n",
      "    input_df=input_df.drop(['B_purchase'], axis=1)\n",
      "    input_df=input_df.drop(['C_purchase'], axis=1)\n",
      "    input_df=input_df.drop(['D_purchase'], axis=1)\n",
      "    input_df=input_df.drop(['E_purchase'], axis=1)\n",
      "    input_df=input_df.drop(['F_purchase'], axis=1)\n",
      "    input_df=input_df.drop(['G_purchase'], axis=1)\n",
      "\n",
      "    \n",
      "    X = input_df.values\n",
      "\n",
      "    skf=StratifiedKFold(y, n_folds=3 )\n",
      "\n",
      "    best_model=None\n",
      "    best_model_score=0\n",
      "    for train_index, test_index in skf:\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        y_train, y_test = y[train_index], y[test_index]\n",
      "        \n",
      "        \n",
      "        n_components = 5\n",
      "        \n",
      "        print(\"Extracting the top %d eigenfaces from %d faces\"\n",
      "              % (n_components, X_train.shape[0]))\n",
      "        t0 = time()\n",
      "        pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\n",
      "        print(\"done in %0.3fs\" % (time() - t0))\n",
      "        \n",
      "        print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
      "        t0 = time()\n",
      "        X_train_pca = pca.transform(X_train)\n",
      "        X_test_pca = pca.transform(X_test)\n",
      "        print(\"done in %0.3fs\" % (time() - t0))\n",
      "        \n",
      "        \n",
      "        ###############################################################################\n",
      "        # Train a SVM classification model\n",
      "        \n",
      "        print(\"Fitting the classifier to the training set\")\n",
      "        t0 = time()\n",
      "        param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
      "                      'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
      "        clf = GridSearchCV(SVC(kernel='rbf', class_weight='auto'), param_grid)\n",
      "        clf = clf.fit(X_train_pca, y_train)\n",
      "        print(\"done in %0.3fs\" % (time() - t0))\n",
      "        print(\"Best estimator found by grid search:\")\n",
      "        print(clf.best_estimator_)\n",
      "        \n",
      "        print \"score:\"+ yName +\":\"+str(clf.score(X_test_pca,y_test))\n",
      "\n",
      "        if best_model==None or best_model_score<clf.score(X_test_pca, y_test):\n",
      "            best_model=clf\n",
      "            best_model_score=clf.score(X_test_pca, y_test_pca)\n",
      "            \n",
      "\n",
      "    trained_model = best_model\n",
      "\n",
      "    return trained_model, best_model_score\n",
      "\n",
      "def predict(test_2_df, model, feature_array, prodStr='A_purchase'):\n",
      "\n",
      "    test_df = test_2_df.copy(deep=True)\n",
      "    test_y = test_df[prodStr]\n",
      "\n",
      "    test_df=test_df[feature_array]\n",
      "\n",
      "    test_X = test_df.values\n",
      "\n",
      "    prediction = model.predict(test_X)\n",
      "    return prediction\n",
      "\n",
      "\n",
      "modelADict={}\n",
      "modelBDict={}\n",
      "modelCDict={}\n",
      "modelDDict={}\n",
      "modelEDict={}\n",
      "modelFDict={}\n",
      "modelGDict={}\n",
      "\n",
      "modelAScores={}\n",
      "modelBScores={}\n",
      "modelCScores={}\n",
      "modelDScores={}\n",
      "modelEScores={}\n",
      "modelFScores={}\n",
      "modelGScores={}\n",
      "\n",
      "for i in range(1,13):\n",
      "    print \"offers:\"+str(i)\n",
      "    train = cleanup(train_sets[i])\n",
      "    modelADict[i], modelAScores[i] = train_pca_SVC(train)\n",
      "    modelBDict[i], modelBScores[i] = train_pca_SVC(train, yName='B_purchase')\n",
      "    modelCDict[i], modelCScores[i] = train_pca_SVC(train, yName='C_purchase')\n",
      "    modelDDict[i], modelDScores[i] = train_pca_SVC(train, yName='D_purchase')\n",
      "    modelEDict[i], modelEScores[i] = train_pca_SVC(train, yName='E_purchase')\n",
      "    modelFDict[i], modelFScores[i] = train_pca_SVC(train, yName='F_purchase')\n",
      "    modelGDict[i], modelGScores[i] = train_pca_SVC(train, yName='G_purchase')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "offers:1\n",
        "Extracting the top 5 eigenfaces from 64672 faces"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done in 0.206s"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}